---
title: "restaurantAnalysis"
author: "Ji Won Chung"
date: "12/5/2017"
output: html_document
---
# Purpose of the File (README)

---
# Import Necessary Packages 
```{r}
library(tree)
library(dplyr)
library(ggplot2)
library(randomForest)
library(rpart.plot)
library(rpart)
```

--- 
#Original Dataset Import & Summary 

## Analysis of the Summary 
Somehting that is apparent from glance is that this dataset has a lot of "Unknown" labels. "Unknown" is a remnant of the python processing file which was used to indicate data that was missing. 
```{r}
restaurantDf = read.csv('restaurantInfo.csv', header = TRUE) 
print("This is the summary information of the original dataset...")
print(summary(restaurantDf))
nObservations = nrow(restaurantDf)
nFactors = ncol(restaurantDf)
```

These are the number of observations in the original dataset
```{r}
print(nObservations)
```
These are the number of columns in the original dataset
```{r}
print(nFactors)
``` 

These are the columns in the original dataset
```{r}
print(colnames(restaurantDf))
```

For reference, we have set the seed to 1. 
```{r}
set.seed(1)
```

---
#Changing Data Types & Reordering Factors 
## Changing Factors to Numeric Data 
"stars" and "review_count" are factor types in R initially. However, they are numbers on an ordinal scale and have a numeric ordering. Thus, we convert the data types of those columns to numeric. 
```{r}
restaurantDf$stars <- as.numeric(restaurantDf$stars)
restaurantDf$review_count <- as.numeric(restaurantDf$review_count)
```

---
## Setting Ordering to Factors 
The columns "BusinessAcceptsCreditCards", "RestaurantsPriceRange2", and "RestaurantsTakeOut" can be considered categorical data types. We extracted the columns above by manually looking through the labels of each columns. However, we examine below that some of the orderings of the factors do not make sense. We arbitrarly ordered the factors from "Unknown" to "negative" to a more "positive" ranking. "Unknown" indicating that we did not have information on the data. "negative" indicating something that we presumed to not be in favor of the customer. "positive" indicating something in favor for the customer. However, this ranking is somewhat subjective. Hence, we explain this part by part for each of the columns. 
```{r}
print(levels(restaurantDf$RestaurantsPriceRange2 )) 
restaurantDf$RestaurantsPriceRange2<- factor(restaurantDf$RestaurantsPriceRange2, levels = c("Unknown", "1.0", "2.0", "3.0", "4.0"))
print(levels(restaurantDf$RestaurantsPriceRange2))

print(levels(restaurantDf$BusinessAcceptsCreditCards )) 
restaurantDf$BusinessAcceptsCreditCards<- factor(restaurantDf$BusinessAcceptsCreditCards, levels = c("Unknown", "False", "True"))
print(levels(restaurantDf$BusinessAcceptsCreditCards )) 


print(levels(restaurantDf$RestaurantsTakeOut )) 
restaurantDf$RestaurantsTakeOut<- factor(restaurantDf$RestaurantsTakeOut, levels = c("Unknown", "False", "True"))
print(levels(restaurantDf$RestaurantsTakeOut )) 
```
---
#Removing Columns 
We removed unnecessary columns "X" and "index" which are remnants of the preprocessing data in python. We also removed "business_id", "city", "neighborhood", and "state" because we were not interested in such fine grain information nor regional information given that our observation set was small. 
```{r}
cleanDf <- subset(restaurantDf, select = -c(X, index, business_id, city, neighborhood, state))
head(cleanDf)
```
---
#Taking the subset of the data 
We took 70% of the dataset for the training model and 30% for the test model. 
```{r}
restaurant_train = cleanDf %>%
  sample_frac(.7)

restaurant_test = cleanDf %>%
  setdiff(restaurant_train)
```

--- 
# Creating a Decision Tree 
## Predicting if the Business is Open using a Classification Tree
```{r}
restaurantsOpen <- rpart(is_open ~ . , data = restaurant_train, method = "class")
rpart.plot(restaurantsOpen) 
```
```{r}
tree_Open = tree(is_open~ ., data = restaurant_train)
print(summary(tree_Open))
tree_Open
plot(tree_Open)
text(tree_Open, pretty = 0)

tree_pred = predict(tree_Open, restaurant_test, type = "class")
table(tree_pred, restaurant_test$is_open)
print((0+1939)/(nrow(restaurant_test))) 
```
This model just seems to predict that restaurants will always be open? Which seems a bit weird for me... 
```{r}
tree_OpenWithoutTakeOut = tree(is_open~ .-RestaurantsTakeOut, data = restaurant_train)
print(summary(tree_OpenWithoutTakeOut))
tree_OpenWithoutTakeOut
plot(tree_OpenWithoutTakeOut)
text(tree_OpenWithoutTakeOut, pretty = 0)

tree_predWithoutTakeOut = predict(tree_OpenWithoutTakeOut, restaurant_test, type = "class")
table(tree_predWithoutTakeOut, restaurant_test$is_open)
print((0+1939)/(nrow(restaurant_test))) 
```

## Predicting Star Reviews of Business using a Regression Tree
```{r}
restaurantsStars <- rpart(stars ~ . , data = restaurant_train, method = "anova")
rpart.plot(restaurantsStars) 


tree_stars = tree(stars~., data = restaurant_train)
print(summary(tree_stars))
tree_stars
plot(tree_stars)
text(tree_stars,  pretty = 0)
```


## Predicting ReviewCounts of Business using a Regression Tree
```{r}
restaurantReviews <- rpart(review_count ~ . , data = restaurant_train, method = "anova")
rpart.plot(restaurantReviews) 


tree_rc = tree(review_count~., data = restaurant_train)
print(summary(tree_rc))
tree_rc
plot(tree_rc)
text(tree_rc,  pretty = 0)
```

#Random Forest: Restaurant is_open
```{r}
rf_isOpen = randomForest(is_open~., 
                         data = cleanDf, 
                         mtry = 3,
                         importance = TRUE)
importance(rf_isOpen)
varImpPlot(rf_isOpen)
```
#Random Forest: Restaurant stars
```{r}
rf_stars = randomForest(stars~., 
                         data = cleanDf, 
                          mtry = 2, 
                         importance = TRUE)
importance(rf_stars)
varImpPlot(rf_stars)
```

#Random Forest: Restaurant reveiw_count
```{r}
rf_reviewCount = randomForest(reveiw_count~., 
                         data = cleanDf, 
                         mtry = 2,
                         importance = TRUE)
importance(rf_reviewCount)
varImpPlot(rf_reviewCount)
```